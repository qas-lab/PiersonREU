{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cafc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4e6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c249c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 14:58:46.012563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 14:58:46.042953: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 14:58:46.042983: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 14:58:46.061848: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 14:58:46.880610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizerFast, TFAutoModelForTokenClassification\n",
    "import pandas as pd \n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930180eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc9b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-07-12 14:58:50.628810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10394 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba94512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b7ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "LOG: Torch allocated Memory:                 0.00 MB\n",
      "LOG: Torch cached Memory:                 0.00 MB\n",
      "LOG: TensorFlow, 0: Current memory usage:             416.42 MB\n",
      "LOG: TensorFlow, 0: Peak memory usage:             505.58 MB\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "model.compile(optimizer='Ftrl', loss='sparse_categorical_crossentropy', metrics = ['Accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c676aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now working with the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2419cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/home/rpierson/Topic_Files/topic_0.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4106ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37da9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1dc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenize function to the 'Combined_Text' column\n",
    "#for x in range(len(train_df)):\n",
    "#    train_df.loc[x, 'Combined_Text'] = tokenize_function(train_df.loc[x, 'Combined_Text'])\n",
    "\n",
    "\n",
    "train_df['Combined_Text'] = train_df['Combined_Text'].apply(tokenize_function)\n",
    "val_df['Combined_Text'] = val_df['Combined_Text'].apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2085a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd609a6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create TensorFlow datasets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mdict\u001b[39m(train_inputs),\n\u001b[1;32m      4\u001b[0m     train_labels\n\u001b[1;32m      5\u001b[0m ))\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mlen\u001b[39m(train_df))\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m      7\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mdict\u001b[39m(val_inputs),\n\u001b[1;32m      9\u001b[0m     val_labels\n\u001b[1;32m     10\u001b[0m ))\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m15\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_inputs),\n",
    "    train_labels\n",
    ")).shuffle(len(train_df)).batch(15)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_inputs),\n",
    "    val_labels\n",
    ")).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282c92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=15  # Adjust the number of epochs based on your needs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf6014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
