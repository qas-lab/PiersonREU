{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c557557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import TFAutoModelForTokenClassification, BertTokenizer\n",
    "#import nltk\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt\n",
    "\n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0764379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a99727",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/home/rpierson/Topic_Files/topic_0.csv')\n",
    "df['Priority'] = label_encoder.fit_transform(df['Priority'])\n",
    "\n",
    "for x in range(len(df)):\n",
    "    if pd.isna(df.iloc[x][\"Combined_Text\"]):\n",
    "        df.at[x, \"Combined_Text\"] = \" \"\n",
    "        \n",
    "count = 0\n",
    "for x in range(len(df)):\n",
    "    if pd.isna(df.iloc[x][\"Combined_Text\"]):\n",
    "        count += count\n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004eee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4af6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a244af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"Combined_Text\"], padding=\"max_length\", truncation=True)\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3367fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Combined_Text'] = train_df['Combined_Text'].apply(remove_links)\n",
    "val_df['Combined_Text'] = val_df['Combined_Text'].apply(remove_links)\n",
    "                                                        \n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e40ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['Combined_Text'] = tf.convert_to_tensor(train_df['Combined_Text'], dtype = tf.string)\n",
    "train_df['Priority'] = tf.convert_to_tensor(train_df['Priority'], dtype = tf.int32)\n",
    "\n",
    "val_df['Combined_Text'] = tf.convert_to_tensor(val_df['Combined_Text'], dtype = tf.string)\n",
    "val_df['Priority'] = tf.convert_to_tensor(val_df['Priority'], dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4684de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeda9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce759f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to tensorflow dataset\n",
    "\n",
    "\n",
    "def df_to_dataset(df, label_column, shuffle=True, batch_size=32):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(label_column)\n",
    "    \n",
    "    # Convert tokenized text to strings\n",
    "    df['Combined_Text'] = df['Combined_Text'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # Convert each column to a tensor with appropriate dtype\n",
    "    for col in df.columns:\n",
    "        if col == 'Combined_Text':\n",
    "            df[col] = df[col].apply(lambda x: tf.convert_to_tensor(str(x), dtype=tf.string))\n",
    "        else:\n",
    "            df[col] = df[col].apply(lambda x: tf.convert_to_tensor(x, dtype=tf.int32))\n",
    "    \n",
    "    # Create a dataset from the dictionary of tensors\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995629e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df_to_dataset(train_df, 'Priority')\n",
    "for batch in train_dataset.take(1):\n",
    "    print(batch)\n",
    "val_dataset = df_to_dataset(val_df, 'Priority', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_df[\"Combined_Text\"].apply(lambda x: tokenize_function({\"Combined_Text\": x}))\n",
    "val_tokenized = val_df[\"Combined_Text\"].apply(lambda x: tokenize_function({\"Combined_Text\": x}))\n",
    "\n",
    "train_df[\"input_ids\"] = train_tokenized.apply(lambda x: x[\"input_ids\"])\n",
    "train_df[\"attention_mask\"] = train_tokenized.apply(lambda x: x[\"attention_mask\"])\n",
    "train_df[\"token_type_ids\"] = train_tokenized.apply(lambda x: x[\"token_type_ids\"])\n",
    "\n",
    "val_df[\"input_ids\"] = val_tokenized.apply(lambda x: x[\"input_ids\"])\n",
    "val_df[\"attention_mask\"] = val_tokenized.apply(lambda x: x[\"attention_mask\"])\n",
    "val_df[\"token_type_ids\"] = val_tokenized.apply(lambda x: x[\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057cc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_label(features, label):\n",
    "    num_classes = 5  # Change this to your actual number of classes\n",
    "    one_hot_label = tf.one_hot(label, depth=num_classes)\n",
    "    return features, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_df.map(one_hot_encode_label)\n",
    "val_dataset = val_df.map(one_hot_encode_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_df.shuffle(len(train_df)).batch(16)\n",
    "val_dataset = val_df.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ad70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.01)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow GPU configuration\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if physical_devices:\n",
    "#    try:\n",
    "#        for device in physical_devices:\n",
    "#            tf.config.experimental.set_memory_growth(device, True)\n",
    "#        print(f\"LOG: TensorFlow GPU devices: {physical_devices}.\", flush=True)\n",
    "#    except RuntimeError as exception:\n",
    "#        print(f\"LOG: TensorFlow GPU devices: {physical_devices}.\", flush=True)\n",
    "#        print(f\"LOG: TensorFlow GPU configuration error: {exception}\", flush=True)\n",
    "#else:\n",
    "#    print(\"ERROR: No TensorFlow GPU devices found.\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "model.compile(optimizer='Ftrl', loss='sparse_categorical_crossentropy', metrics = ['Accuracy', 'Precision', 'Recall'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14116783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_df['Priority']\n",
    ")).shuffle(len(train_df)).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_df['Priority']\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_df,\n",
    "    validation_data=val_df,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5ca4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
