{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204b13ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/rpierson/anaconda3/envs/firstenvi/lib/python3.11/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /home/rpierson/anaconda3/envs/firstenvi/lib/python3.11/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /home/rpierson/anaconda3/envs/firstenvi/lib/python3.11/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/rpierson/anaconda3/envs/firstenvi/lib/python3.11/site-packages (from nltk) (2023.10.3)\r\n",
      "Requirement already satisfied: tqdm in /home/rpierson/anaconda3/envs/firstenvi/lib/python3.11/site-packages (from nltk) (4.66.4)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rpierson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords #Word Stop\n",
    "from nltk.tokenize import word_tokenize #Tokenization & Word Stop\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation + '``'+ '`'+ ''+ ',' + '/')\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7c2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Preprocessing subpipeline\n",
    "class PreprocessingPineline:\n",
    "    def __init__(self, stop_words, punctuation):\n",
    "        self.punctuation = punctuation\n",
    "        self.stop_words = stop_words\n",
    "        self.data = None\n",
    "        self.tokens = None        \n",
    "        \n",
    "    def data_to_tokens(self, data):\n",
    "        self.data = data\n",
    "        self.tokens = self.data.astype(str).apply(word_tokenize)\n",
    "        self.tokens = [[word for word in tokens if word.lower() not in stop_words and word not in punctuation] for tokens in self.tokens]\n",
    "        return self.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d819cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Topic Modeling subPipeline\n",
    "class LDATopicModelPipeline:\n",
    "    def __init__(self, lda_model_path, vectorizer_path):\n",
    "        self.lda_model_path = lda_model_path\n",
    "        self.vectorizer_path = vectorizer_path\n",
    "        self.lda = None\n",
    "        self.vectorizer = None\n",
    "        \n",
    "    def load_model(self):\n",
    "        self.lda = joblib.load(self.lda_model_path)\n",
    "        self.vectorizer = joblib.load(self.vectorizer_path)\n",
    "        \n",
    "    def topic_distributions(self, new_documents):\n",
    "        if self.lda is None or self.vectorizer is None:\n",
    "            self.load_model()\n",
    "            \n",
    "        if isinstance(new_documents[\"Combined_Text\"], list):\n",
    "            # If new_documents is a list of strings\n",
    "            texts = new_documents\n",
    "        elif isinstance(new_documents[\"Combined_Text\"], pd.Series):\n",
    "            # If new_documents is a Pandas Series (assuming it's a single column from a DataFrame)\n",
    "            texts = new_documents[\"Combined_Text\"].tolist()\n",
    "            \n",
    "        else:\n",
    "            raise TypeError(\"Input data should be a list, Pandas Series, or DataFrame of strings.\")\n",
    "            \n",
    "        x = self.vectorizer.transform(texts)\n",
    "        topic_distributions = self.lda.transform(x)\n",
    "        return topic_distributions\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        return self.vectorizer\n",
    "    \n",
    "    def append_topics(self, data, topic_distributions):\n",
    "        topics = []\n",
    "        for topic_dist in topic_distributions:\n",
    "            dominant_topic = topic_dist.argmax()\n",
    "            topics.append(dominant_topic)\n",
    "            \n",
    "        data['Topic'] = topics\n",
    "        return data\n",
    "            \n",
    "#gives necessary files to process information\n",
    "#use through this syntax: topic_distributions = topic_model.topic_distributions(new_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7cddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an Text Classification subpipeline\n",
    "class TextClassificationNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.documents = None\n",
    "        self.vectorizer = None\n",
    "        self.bayes_trained = None\n",
    "        \n",
    "        \n",
    "    def load_model(self, topic_num):\n",
    "        #Use Trained Text Classifier Based on Topic Number\n",
    "         for x in [topic_num]:\n",
    "            self.bayes_trained = joblib.load(f'/home/rpierson/githubPierson/bayes/topic_pred_{x}.pkl')\n",
    "            self.vectorizer = joblib.load(f'/home/rpierson/githubPierson/bayes/vec_{x}.pkl')\n",
    "    def priority(self, documents):\n",
    "        self.num_topics = documents['Topic'].drop_duplicates().values\n",
    "        documents[\"Predicted_Priority\"] = \"\" \n",
    "        self.documents = documents\n",
    "        \n",
    "        for topic_num in self.num_topics:\n",
    "            self.load_model(topic_num)\n",
    "            for i in self.documents.index: \n",
    "                if self.documents.loc[i, 'Topic'] == topic_num:\n",
    "                    text = self.documents.loc[i, \"Combined_Text\"]\n",
    "                    vector = self.vectorizer.transform([text]).toarray().reshape(1, -1)\n",
    "                    prediction = self.bayes_trained.predict(vector)\n",
    "                    self.documents.at[i, \"Predicted_Priority\"] = prediction[0]\n",
    "        return self.documents\n",
    "        \n",
    "    \n",
    "        #topic_prediction_function.predict(topic_validation_data.toarray())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2df03af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AccuracyAssessment:\n",
    "    def __init__(self, priority_levels):\n",
    "        self.actual_priority = None\n",
    "        self.predicted_priority = None\n",
    "        self.true_pos = 0\n",
    "        self.false_pos = 0\n",
    "        self.false_neg = 0\n",
    "        self.num_priority_levels = priority_levels\n",
    "        self.confusion_matrix = np.zeros((self.num_priority_levels, self.num_priority_levels), dtype=int)\n",
    "    \n",
    "    def update_vals(self, actual, predicted):\n",
    "        self.actual_priority = actual.astype(int)\n",
    "        self.predicted_priority = predicted.astype(int)\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        for i in range(len(self.actual_priority)):\n",
    "            true_idx = self.actual_priority[i] - 1\n",
    "            pred_idx = self.predicted_priority[i] - 1\n",
    "            self.confusion_matrix[true_idx, pred_idx] += 1\n",
    "    \n",
    "    def calc_metrics(self, class_index):\n",
    "        self.true_pos = self.confusion_matrix[class_index, class_index]\n",
    "        self.false_pos = np.sum(self.confusion_matrix[:, class_index]) - self.true_pos\n",
    "        self.false_neg = np.sum(self.confusion_matrix[class_index, :]) - self.true_pos\n",
    "    \n",
    "    def precision(self, class_index):\n",
    "        self.calc_metrics(class_index)\n",
    "        \n",
    "        if self.true_pos + self.false_pos == 0:\n",
    "            return 0\n",
    "        precision = self.true_pos / (self.true_pos + self.false_pos)\n",
    "        \n",
    "        return precision\n",
    "    \n",
    "    def recall(self, class_index):\n",
    "        self.calc_metrics(class_index)\n",
    "        \n",
    "        if self.true_pos + self.false_neg == 0:\n",
    "            return 0\n",
    "        \n",
    "        recall = self.true_pos / (self.true_pos + self.false_neg)\n",
    "        \n",
    "        return recall\n",
    "    \n",
    "    def fmeasure(self, class_index):\n",
    "        precision = self.precision(class_index)\n",
    "        recall = self.recall(class_index)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            return 0\n",
    "        \n",
    "        fmeasure = (2 * precision * recall) / (precision + recall)\n",
    "        \n",
    "        return fmeasure\n",
    "    \n",
    "    def microAnalysis(self):\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f_measures = []\n",
    "        for i in range(self.num_priority_levels):\n",
    "            precision_score = self.precision(i)\n",
    "            recall_score = self.recall(i)\n",
    "            f_measure_score = self.fmeasure(i)\n",
    "            \n",
    "            precisions.append(precision_score)\n",
    "            recalls.append(recall_score)\n",
    "            f_measures.append(f_measure_score)\n",
    "        \n",
    "        micro_precision = sum(precisions) / sum(precisions + recalls)\n",
    "        micro_recall = sum(precisions) / sum(precisions + f_measures)\n",
    "        micro_fmeasure = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)\n",
    "        print(f\"Micro-Analysis for Priority Levels: Precision = {micro_precision:.4f}, Recall={micro_recall:.4f}, F-measure={micro_fmeasure:.4f}\")\n",
    "   \n",
    "    def macroAnalysis(self):\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f_measures = []\n",
    "        for i in range(self.num_priority_levels):\n",
    "            precision_score = self.precision(i)\n",
    "            recall_score = self.recall(i)\n",
    "            f_measure_score = self.fmeasure(i)\n",
    "            \n",
    "            precisions.append(precision_score)\n",
    "            recalls.append(recall_score)\n",
    "            f_measures.append(f_measure_score)\n",
    "\n",
    "        macro_precision = sum(precisions) / len(precisions)\n",
    "        macro_recall = sum(recalls) / len(recalls)\n",
    "        macro_fmeasure = sum(f_measures) / len(f_measures)\n",
    "        print(f\"Macro-Analysis for Priority Levels: Precision = {macro_precision:.4f}, Recall={macro_recall:.4f}, F-measure={macro_fmeasure:.4f}\")\n",
    "    def printAssessment(self):\n",
    "        for i in range(self.num_priority_levels):\n",
    "            precision_score = self.precision(i)\n",
    "            recall_score = self.recall(i)\n",
    "            f_measure_score = self.fmeasure(i)\n",
    "    \n",
    "            print(f\"Priority P{i+1}: Precision={precision_score:.4f}, Recall={recall_score:.4f}, F-measure={f_measure_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc04cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def priority_pipeline(data, actual):\n",
    "    data = data\n",
    "    #PreProcessing\n",
    "   # preprocess = PreprocessingPineline(stop_words, punctuation)\n",
    "   # data = preprocess.data_to_tokens(data)\n",
    "    \n",
    "    #Topic Modeling (Insert Trained Model Here, Save as a .pth)\n",
    "    lda_model_path = '/home/rpierson/PiersonREU/extracted/lda.pkl'\n",
    "    vectorizer_path = '/home/rpierson/PiersonREU/extracted/vec.pkl'\n",
    "    topic_model = LDATopicModelPipeline(lda_model_path, vectorizer_path)\n",
    "    topic_model.load_model()\n",
    "    df = pd.DataFrame(columns = ['Combined_Text', 'Topic'])\n",
    "    df['Combined_Text'] = data\n",
    "    topic_distributions = topic_model.topic_distributions(df)\n",
    "    data = topic_model.append_topics(df, topic_distributions)\n",
    "    print(df)\n",
    "    vectorizer = topic_model.get_vectorizer()\n",
    "    \n",
    "    #Text Classification Per Topic (Insert Trained Model Here, Save as a .pth)\n",
    "    nb = TextClassificationNaiveBayes()\n",
    "    data = nb.priority(df)\n",
    "    print(data[\"Predicted_Priority\"])\n",
    "    print(data.groupby('Predicted_Priority').sum())\n",
    "    \n",
    "    #Accuracy and Evaluation\n",
    "    assessment = AccuracyAssessment(priority_levels = 5)\n",
    "    assessment.update_vals(actual, data[\"Predicted_Priority\"])\n",
    "    assessment.printAssessment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d387007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def priority_pipeline_without_assessment(data):\n",
    "    data = data\n",
    "    #PreProcessing\n",
    "   # preprocess = PreprocessingPineline(stop_words, punctuation)\n",
    "   # data = preprocess.data_to_tokens(data)\n",
    "    \n",
    "    #Topic Modeling (Insert Trained Model Here, Save as a .pth)\n",
    "    lda_model_path = '/home/rpierson/PiersonREU/extracted/lda.pkl'\n",
    "    vectorizer_path = '/home/rpierson/PiersonREU/extracted/vec.pkl'\n",
    "    topic_model = LDATopicModelPipeline(lda_model_path, vectorizer_path)\n",
    "    topic_model.load_model()\n",
    "    df = pd.DataFrame(columns = ['Combined_Text', 'Topic'])\n",
    "    df['Combined_Text'] = data\n",
    "    topic_distributions = topic_model.topic_distributions(df)\n",
    "    data = topic_model.append_topics(df, topic_distributions)\n",
    "    print(df)\n",
    "    vectorizer = topic_model.get_vectorizer()\n",
    "    \n",
    "    #Text Classification Per Topic (Insert Trained Model Here, Save as a .pth)\n",
    "    nb = TextClassificationNaiveBayes()\n",
    "    data = nb.priority(df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f5fd2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "to_see_results = pd.read_csv('/home/rpierson/PiersonREU/extracted/train_dataset_0.csv')\n",
    "to_see_results.head()\n",
    "\n",
    "actual = [to_see_results[\"Priority\"]]\n",
    "actual_df = pd.DataFrame(actual)\n",
    "actual_df = actual_df.transpose()\n",
    "actual_df\n",
    "\n",
    "Combined_Text = [to_see_results[\"Combined_Text\"]]\n",
    "df = pd.DataFrame(Combined_Text)\n",
    "df = df.transpose()\n",
    "df\n",
    "label_map = {'P1': 1, 'P2': 2, 'P3': 3, 'P4': 4, 'P5': 5}\n",
    "to_see_results['Priority'] = to_see_results['Priority'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe7952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6d187ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Combined_Text  Topic\n",
      "0      Usability issue with external editors (1GE6IRL...      9\n",
      "1      CC Discussion: local versioning (1GAT3PL) Team...      9\n",
      "2      Manage/unmanage support and policies (1GALAEG)...      9\n",
      "3      API: ISharingManager::load mapping vcm project...      9\n",
      "4      API - VCM event notification (1G8G6RR) Team Th...      9\n",
      "...                                                  ...    ...\n",
      "40869  wrong size computation for Link widget SWT I20...      6\n",
      "40870  Visibility Property for TableColumns SWT Prior...      9\n",
      "40871  Invalid required space shown on feature instal...      9\n",
      "40872  Widget disposed exception after updating incom...      4\n",
      "40873  Widget is disposed in WorkbenchContextSupport....      9\n",
      "\n",
      "[40874 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m priority_pipeline(data \u001b[38;5;241m=\u001b[39m to_see_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined_Text\u001b[39m\u001b[38;5;124m'\u001b[39m], actual \u001b[38;5;241m=\u001b[39m to_see_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPriority\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mpriority_pipeline\u001b[0;34m(data, actual)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Text Classification Per Topic (Insert Trained Model Here, Save as a .pth)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m nb \u001b[38;5;241m=\u001b[39m TextClassificationNaiveBayes()\n\u001b[0;32m---> 21\u001b[0m data \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mpriority(df)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted_Priority\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Priority\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mTextClassificationNaiveBayes.priority\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(topic_num)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39mindex: \n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m topic_num:\n\u001b[1;32m     23\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined_Text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m         vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mtransform([text])\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/firstenvi/lib/python3.11/site-packages/pandas/core/indexing.py:1182\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1180\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m is_iterator(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1181\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m-> 1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/firstenvi/lib/python3.11/site-packages/pandas/core/indexing.py:1277\u001b[0m, in \u001b[0;36m_LocIndexer._is_scalar_access\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m ax\u001b[38;5;241m.\u001b[39m_supports_partial_string_indexing:\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;66;03m# partial string indexing, df.loc['2000', 'A']\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m         \u001b[38;5;66;03m# should not be considered scalar\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ax\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m   1278\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/firstenvi/lib/python3.11/site-packages/pandas/core/indexes/base.py:6312\u001b[0m, in \u001b[0;36mIndex._index_as_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6309\u001b[0m         missing \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(target), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[1;32m   6310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m no_matches, missing\n\u001b[0;32m-> 6312\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   6313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_as_unique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6315\u001b[0m \u001b[38;5;124;03m    Whether we should treat this as unique for the sake of\u001b[39;00m\n\u001b[1;32m   6316\u001b[0m \u001b[38;5;124;03m    get_indexer vs get_indexer_non_unique.\u001b[39;00m\n\u001b[1;32m   6317\u001b[0m \n\u001b[1;32m   6318\u001b[0m \u001b[38;5;124;03m    For IntervalIndex compat.\u001b[39;00m\n\u001b[1;32m   6319\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "priority_pipeline(data = to_see_results['Combined_Text'], actual = to_see_results['Priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014b2c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level = list(range(1, 6))\n",
    "level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccce0512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Combined_Text  Topic\n",
      "0      Usability issue with external editors (1GE6IRL...      9\n",
      "1      CC Discussion: local versioning (1GAT3PL) Team...      9\n",
      "2      Manage/unmanage support and policies (1GALAEG)...      9\n",
      "3      API: ISharingManager::load mapping vcm project...      9\n",
      "4      API - VCM event notification (1G8G6RR) Team Th...      9\n",
      "...                                                  ...    ...\n",
      "40869  wrong size computation for Link widget SWT I20...      6\n",
      "40870  Visibility Property for TableColumns SWT Prior...      9\n",
      "40871  Invalid required space shown on feature instal...      9\n",
      "40872  Widget disposed exception after updating incom...      4\n",
      "40873  Widget is disposed in WorkbenchContextSupport....      9\n",
      "\n",
      "[40874 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "new_df = priority_pipeline_without_assessment(data = to_see_results['Combined_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4073c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assessment = AccuracyAssessment(5)\n",
    "assessment.update_vals(to_see_results['Priority'], new_df[\"Predicted_Priority\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e38896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority P1: Precision=0.4489, Recall=0.9905, F-measure=0.6178\n",
      "Priority P2: Precision=0.6635, Recall=0.8588, F-measure=0.7486\n",
      "Priority P3: Precision=1.0000, Recall=0.8132, F-measure=0.8970\n",
      "Priority P4: Precision=0.5558, Recall=0.8977, F-measure=0.6865\n",
      "Priority P5: Precision=0.3335, Recall=0.9989, F-measure=0.5000\n"
     ]
    }
   ],
   "source": [
    "assessment.printAssessment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52770af",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pd.DataFrame(to_see_results['Priority'])\n",
    "predicted = pd.DataFrame(new_df[\"Predicted_Priority\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_level = []\n",
    "pred_level = []\n",
    "priority_level = 1\n",
    "        \n",
    "for idx in range(len(actual)):\n",
    "    if actual.loc[idx,'Priority'] == priority_level:\n",
    "        true_level[priority_level].append(actual[idx], index = False)\n",
    "        pred_level[priority_level].append(predicted[idx] if actual[idx] == priority_level else 6, index = False)\n",
    "        accuracy_result = accuracy_result.append(accuracy_score(true_level[priority_level], pred_level[priority_level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1656f4a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-Analysis for Priority Levels: Precision = 0.6003, Recall=0.9118, F-measure=0.6900\n"
     ]
    }
   ],
   "source": [
    "assessment.macroAnalysis()\n",
    "#It treats each class equally, so classes with fewer instances have the same weight as those with more instances, which may not reflect the practical importance or impact of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "39fa9124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Analysis for Priority Levels: Precision = 0.3970, Recall=0.4653, F-measure=0.4284\n"
     ]
    }
   ],
   "source": [
    "assessment.microAnalysis()\n",
    "#different aggregation strategies: Micro-averaging gives equal weight to each instance\n",
    "# Macro-averaging gives equal weight to each class\n",
    "#It can be skewed by classes with more instances, giving them more influence over the final metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172785bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use micro-averaging if you want to emphasize overall performance across all instances equally.\n",
    "#Use macro-averaging if you want to evaluate and compare performance across different classes equally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
