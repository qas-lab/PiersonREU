{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c557557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 18:39:40.727260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-11 18:39:40.757827: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-11 18:39:40.757860: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-11 18:39:40.776754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 18:39:41.585344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import TFAutoModelForSequenceClassification, BertTokenizer\n",
    "#import nltk\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt\n",
    "\n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0764379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-07-11 18:39:46.905988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10532 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.907093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10532 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.908030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10532 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.908900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10532 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.909859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 10532 MB memory:  -> device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.910785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 10532 MB memory:  -> device: 5, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.911661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 10532 MB memory:  -> device: 6, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1\n",
      "2024-07-11 18:39:46.912554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 10532 MB memory:  -> device: 7, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a99727",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23d14c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'/home/rpierson/Topic_Files/topic_0.csv')\n",
    "df['Priority'] = label_encoder.fit_transform(df['Priority'])\n",
    "\n",
    "for x in range(len(df)):\n",
    "    if pd.isna(df.iloc[x][\"Combined_Text\"]):\n",
    "        df.at[x, \"Combined_Text\"] = \" \"\n",
    "        \n",
    "count = 0\n",
    "for x in range(len(df)):\n",
    "    if pd.isna(df.iloc[x][\"Combined_Text\"]):\n",
    "        count += count\n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2004eee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>add new versions of equinox.jetty; orbit bundl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Help files doesnt open User Assistance Build I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>compile error in pde api module from the sourc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>compile error with org.eclipse.help.base due t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>upgrade to Orbit stable build S20080427194908 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Combined_Text  Priority\n",
       "1025  add new versions of equinox.jetty; orbit bundl...         2\n",
       "1026  Help files doesnt open User Assistance Build I...         2\n",
       "1027  compile error in pde api module from the sourc...         2\n",
       "1028  compile error with org.eclipse.help.base due t...         2\n",
       "1029  upgrade to Orbit stable build S20080427194908 ...         2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4af6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a244af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"Combined_Text\"], padding=\"max_length\", truncation=True)\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3367fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Combined_Text'] = train_df['Combined_Text'].apply(remove_links)\n",
    "val_df['Combined_Text'] = val_df['Combined_Text'].apply(remove_links)\n",
    "                                                        \n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e40ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['Combined_Text'] = tf.convert_to_tensor(train_df['Combined_Text'], dtype = tf.string)\n",
    "train_df['Priority'] = tf.convert_to_tensor(train_df['Priority'], dtype = tf.int32)\n",
    "\n",
    "val_df['Combined_Text'] = tf.convert_to_tensor(val_df['Combined_Text'], dtype = tf.string)\n",
    "val_df['Priority'] = tf.convert_to_tensor(val_df['Priority'], dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e4684de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>b'[website] Update links to IBM docs SWT  ; Th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>b'Help Contents Frame Empty User Assistance Hi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>b'Spelling error in Ant Code Formatter prefere...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>b'javadoc warning in build 200611140927 Compar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>b'Searching in help -&gt; document not indexed  m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>b'NL Fix for help_home.html User Assistance Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>b'&lt;input&gt; tag Error. Ant ANT run..; ; &lt;input&gt; ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>b'[Help] Improve search by keyword User Assist...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>b'[CVS Help] ref-46.htm in help docs is empty ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>b'[Webapp] Build script needs to be updated Us...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Combined_Text  Priority\n",
       "995  b'[website] Update links to IBM docs SWT  ; Th...         2\n",
       "507  b'Help Contents Frame Empty User Assistance Hi...         2\n",
       "334  b'Spelling error in Ant Code Formatter prefere...         2\n",
       "848  b'javadoc warning in build 200611140927 Compar...         2\n",
       "294  b'Searching in help -> document not indexed  m...         2\n",
       "..                                                 ...       ...\n",
       "87   b'NL Fix for help_home.html User Assistance Th...         0\n",
       "330  b'<input> tag Error. Ant ANT run..; ; <input> ...         2\n",
       "466  b'[Help] Improve search by keyword User Assist...         3\n",
       "121  b'[CVS Help] ref-46.htm in help docs is empty ...         1\n",
       "860  b'[Webapp] Build script needs to be updated Us...         2\n",
       "\n",
       "[824 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d079ce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>b'Interfaces not exported User Assistance I tr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>b'Help uses xerces implementation classes inst...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>b'duplicate options not handled the same as cm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>b'NL File errors Releng Please fix the followi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>b'Document the error handling in user and isv ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>b'eclipse build script is not a proper Bourne ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>b'extradir help topics not indexed when plugin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>b'Infocenter: servlet classes not found. User ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>b'Warnings in latest integration build User As...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>b'Implementation of help.buildHelpIndex ant ta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Combined_Text  Priority\n",
       "31   b'Interfaces not exported User Assistance I tr...         2\n",
       "109  b'Help uses xerces implementation classes inst...         2\n",
       "136  b'duplicate options not handled the same as cm...         1\n",
       "88   b'NL File errors Releng Please fix the followi...         0\n",
       "918  b'Document the error handling in user and isv ...         2\n",
       "..                                                 ...       ...\n",
       "482  b'eclipse build script is not a proper Bourne ...         2\n",
       "545  b'extradir help topics not indexed when plugin...         2\n",
       "110  b'Infocenter: servlet classes not found. User ...         1\n",
       "514  b'Warnings in latest integration build User As...         2\n",
       "602  b'Implementation of help.buildHelpIndex ant ta...         2\n",
       "\n",
       "[206 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeda9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce759f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to tensorflow dataset\n",
    "\n",
    "\n",
    "def df_to_dataset(df, label_column, shuffle=True, batch_size=32):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(label_column)\n",
    "    \n",
    "    # Convert tokenized text to strings\n",
    "    df['Combined_Text'] = df['Combined_Text'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # Convert each column to a tensor with appropriate dtype\n",
    "    for col in df.columns:\n",
    "        if col == 'Combined_Text':\n",
    "            df[col] = df[col].apply(lambda x: tf.convert_to_tensor(str(x), dtype=tf.string))\n",
    "        else:\n",
    "            df[col] = df[col].apply(lambda x: tf.convert_to_tensor(x, dtype=tf.int32))\n",
    "    \n",
    "    # Create a dataset from the dictionary of tensors\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "995629e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m df_to_dataset(train_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPriority\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mdf_to_dataset\u001b[0;34m(df, label_column, shuffle, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpop(label_column)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert tokenized text to strings\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined_Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined_Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert each column to a tensor with appropriate dtype\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mdf_to_dataset.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpop(label_column)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert tokenized text to strings\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined_Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined_Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert each column to a tensor with appropriate dtype\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "train_dataset = df_to_dataset(train_df, 'Priority')\n",
    "for batch in train_dataset.take(1):\n",
    "    print(batch)\n",
    "val_dataset = df_to_dataset(val_df, 'Priority', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_df[\"Combined_Text\"].apply(lambda x: tokenize_function({\"Combined_Text\": x}))\n",
    "val_tokenized = val_df[\"Combined_Text\"].apply(lambda x: tokenize_function({\"Combined_Text\": x}))\n",
    "\n",
    "train_df[\"input_ids\"] = train_tokenized.apply(lambda x: x[\"input_ids\"])\n",
    "train_df[\"attention_mask\"] = train_tokenized.apply(lambda x: x[\"attention_mask\"])\n",
    "train_df[\"token_type_ids\"] = train_tokenized.apply(lambda x: x[\"token_type_ids\"])\n",
    "\n",
    "val_df[\"input_ids\"] = val_tokenized.apply(lambda x: x[\"input_ids\"])\n",
    "val_df[\"attention_mask\"] = val_tokenized.apply(lambda x: x[\"attention_mask\"])\n",
    "val_df[\"token_type_ids\"] = val_tokenized.apply(lambda x: x[\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "057cc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_label(features, label):\n",
    "    num_classes = 5  # Change this to your actual number of classes\n",
    "    one_hot_label = tf.one_hot(label, depth=num_classes)\n",
    "    return features, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "657e3d48",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "one_hot_encode_label() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mmap(one_hot_encode_label)\n\u001b[1;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_df\u001b[38;5;241m.\u001b[39mmap(one_hot_encode_label)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/frame.py:10468\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(infer)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/frame.py:10466\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: one_hot_encode_label() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "train_dataset = train_df.map(one_hot_encode_label)\n",
    "val_dataset = val_df.map(one_hot_encode_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_df.shuffle(len(train_df)).batch(16)\n",
    "val_dataset = val_df.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ad70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.01)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow GPU configuration\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if physical_devices:\n",
    "#    try:\n",
    "#        for device in physical_devices:\n",
    "#            tf.config.experimental.set_memory_growth(device, True)\n",
    "#        print(f\"LOG: TensorFlow GPU devices: {physical_devices}.\", flush=True)\n",
    "#    except RuntimeError as exception:\n",
    "#        print(f\"LOG: TensorFlow GPU devices: {physical_devices}.\", flush=True)\n",
    "#        print(f\"LOG: TensorFlow GPU configuration error: {exception}\", flush=True)\n",
    "#else:\n",
    "#    print(\"ERROR: No TensorFlow GPU devices found.\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "model.compile(optimizer='Ftrl', loss='sparse_categorical_crossentropy', metrics = ['Accuracy', 'Precision', 'Recall'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14116783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_df['Priority']\n",
    ")).shuffle(len(train_df)).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_df['Priority']\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f342c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_df,\n",
    "    validation_data=val_df,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5ca4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
