{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cafc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4e6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c249c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 21:44:26.262406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 21:44:26.285205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 21:44:26.285232: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 21:44:26.299736: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 21:44:27.087979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "import pandas as pd \n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930180eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:0\"))\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc9b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba94512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 21:44:31.395969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10532 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b7ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "LOG: Torch allocated Memory:                 0.00 MB\n",
      "LOG: Torch cached Memory:                 0.00 MB\n",
      "LOG: TensorFlow, 0: Current memory usage:             0.00 MB\n",
      "LOG: TensorFlow, 0: Peak memory usage:             0.00 MB\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "#model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c676aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now working with the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2419cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/home/rpierson/Topic_Files/topic_0.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4106ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding= \"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37da9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1dc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenize function to the 'Combined_Text' column\n",
    "#for x in range(len(train_df)):\n",
    "#    train_df.loc[x, 'Combined_Text'] = tokenize_function(train_df.loc[x, 'Combined_Text'])\n",
    "\n",
    "\n",
    "#train_df['Combined_Text'] = train_df['Combined_Text'].apply(tokenize_function)\n",
    "#val_df['Combined_Text'] = val_df['Combined_Text'].apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2085a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(\n",
    "    train_df['Combined_Text'].tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    val_df['Combined_Text'].tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3282c92c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_inputs = {\n",
    "    'input_ids': tf.constant(train_encodings['input_ids']),\n",
    "    'attention_mask': tf.constant(train_encodings['attention_mask'])\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    'input_ids': tf.constant(val_encodings['input_ids']),\n",
    "    'attention_mask': tf.constant(val_encodings['attention_mask'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9de4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.constant(train_df['Priority'].values)  # Shape (num_samples,)\n",
    "val_labels = tf.constant(val_df['Priority'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a88be35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(824,), dtype=int64, numpy=\n",
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 1,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 1, 3, 3, 3, 1, 2, 3, 3, 3, 4, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3,\n",
       "       3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1,\n",
       "       3, 3, 3, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 2, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       3, 3, 3, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 1,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 4, 3, 3,\n",
       "       3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3,\n",
       "       3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 1, 3, 4, 2, 3])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aaf1968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input_ids shape: (824, 512)\n",
      "Train attention_mask shape: (824, 512)\n",
      "Val input_ids shape: (206, 512)\n",
      "Val attention_mask shape: (206, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train input_ids shape:\", tf.constant(train_encodings['input_ids']).shape)\n",
    "print(\"Train attention_mask shape:\", tf.constant(train_encodings['attention_mask']).shape)\n",
    "print(\"Val input_ids shape:\", tf.constant(val_encodings['input_ids']).shape)\n",
    "print(\"Val attention_mask shape:\", tf.constant(val_encodings['attention_mask']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292c6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_encodings, train_labels)).shuffle(len(train_df)).batch(15)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_encodings, val_labels)).batch(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd609a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#    dict(train_encodings),\n",
    "#    train_df['Priority']\n",
    "#)).shuffle(len(train_df)).batch(15)\n",
    "\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#    dict(val_encodings),\n",
    "#    val_df['Priority']\n",
    "#)).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d13d7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch input_ids shape: (15, 512)\n",
      "Train batch attention_mask shape: (15, 512)\n",
      "Train batch labels shape: (15,)\n",
      "Val batch input_ids shape: (15, 512)\n",
      "Val batch attention_mask shape: (15, 512)\n",
      "Val batch labels shape: (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 21:44:34.511253: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-12 21:44:34.521590: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_dataset.take(1):\n",
    "    print(\"Train batch input_ids shape:\", inputs['input_ids'].shape)\n",
    "    print(\"Train batch attention_mask shape:\", inputs['attention_mask'].shape)\n",
    "    print(\"Train batch labels shape:\", labels.shape)\n",
    "\n",
    "for inputs, labels in val_dataset.take(1):\n",
    "    print(\"Val batch input_ids shape:\", inputs['input_ids'].shape)\n",
    "    print(\"Val batch attention_mask shape:\", inputs['attention_mask'].shape)\n",
    "    print(\"Val batch labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ea5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f54120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fc9d131",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Batch structure = <class 'tuple'>\n",
      "({'input_ids': <tf.Tensor: shape=(15, 512), dtype=int32, numpy=\n",
      "array([[  101,  1031,  2393, ...,     0,     0,     0],\n",
      "       [  101,  3945, 12117, ...,     0,     0,     0],\n",
      "       [  101,  9986,  8917, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  2770, 13232, ...,     0,     0,     0],\n",
      "       [  101,  1031,  3145, ...,     0,     0,     0],\n",
      "       [  101,  4773, 16602, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(15, 512), dtype=int32, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(15, 512), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}, <tf.Tensor: shape=(15,), dtype=int64, numpy=array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2])>)\n",
      "Step 1: Batch structure = <class 'tuple'>\n",
      "({'input_ids': <tf.Tensor: shape=(15, 512), dtype=int32, numpy=\n",
      "array([[  101,  1031, 16602, ...,     0,     0,     0],\n",
      "       [  101,  1006,  8983, ...,     0,     0,     0],\n",
      "       [  101,  1026,  7953, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  6881, 10697, ...,     0,     0,     0],\n",
      "       [  101,  8651,  1997, ...,     0,     0,     0],\n",
      "       [  101,  1031, 17174, ...,  3231,  1012,   102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(15, 512), dtype=int32, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(15, 512), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}, <tf.Tensor: shape=(15,), dtype=int64, numpy=array([3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])>)\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_dataset):\n",
    "    print(f\"Step {step}: Batch structure = {type(batch)}\")\n",
    "    print(batch)\n",
    "    if step >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35ba1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b982ec16",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'zero_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'zero_grad'"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 15\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for step, batch in enumerate(train_dataset):\n",
    "        # Extracting the input tensors and labels\n",
    "        inputs = torch.tensor(batch[0]['input_ids'].numpy()).squeeze().to(device)\n",
    "        token_type_ids = torch.tensor(batch[0]['token_type_ids'].numpy()).squeeze().to(device)\n",
    "        attention_mask = torch.tensor(batch[0]['attention_mask'].numpy()).squeeze().to(device)\n",
    "        labels = torch.tensor(batch[1].numpy()-1).squeeze().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=inputs, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Optional: Calculate and print metrics, etc.\n",
    "        total_loss += loss.item()\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{step + 1}/{len(train_dataset)}], Loss: {total_loss / 100:.4f}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "    # Optional: Perform evaluation or save checkpoints at the end of each epoch\n",
    "    # Example:\n",
    "    # evaluate_model()\n",
    "    # save_checkpoint()\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf6014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 22:11:31.044229: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-12 22:19:09.116185: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-12 22:26:30.668621: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-12 22:32:02.561043: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-12 22:37:44.161837: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = GradScaler()  \n",
    "# Assuming train_dataset is your DataLoader or Dataset\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for step, batch in enumerate(train_dataset):\n",
    "        inputs = torch.tensor(batch[0]['input_ids'].numpy()).squeeze().to(device)\n",
    "        token_type_ids = torch.tensor(batch[0]['token_type_ids'].numpy()).squeeze().to(device)\n",
    "        attention_mask = torch.tensor(batch[0]['attention_mask'].numpy()).squeeze().to(device)\n",
    "        labels = torch.tensor(batch[1].numpy() - 1).to(device)  # Adjust labels to start from 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(input_ids=inputs, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            logits = logits.reshape(-1, num_classes)\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{step + 1}/{len(train_dataset)}], Loss: {total_loss / 100:.4f}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2b88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ac5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
