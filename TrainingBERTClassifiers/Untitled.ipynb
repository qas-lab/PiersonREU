{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c249c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 20:12:27.249454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-10 20:12:27.278769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-10 20:12:27.278794: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-10 20:12:27.296956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 20:12:28.101411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc9b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 20:12:32.653978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 133 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.655136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 135 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.656072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 135 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.656948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 135 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.657821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 135 MB memory:  -> device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.658794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 135 MB memory:  -> device: 5, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.659706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 135 MB memory:  -> device: 6, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1\n",
      "2024-07-10 20:12:32.660554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 135 MB memory:  -> device: 7, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba94512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b7ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-07-10 20:12:45.161964: W external/local_tsl/tsl/framework/bfc_allocator.cc:487] Allocator (GPU_0_bfc) ran out of memory trying to allocate 89.42MiB (rounded to 93763584)requested by op Mul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-07-10 20:12:45.162009: I external/local_tsl/tsl/framework/bfc_allocator.cc:1044] BFCAllocator dump for GPU_0_bfc\n",
      "2024-07-10 20:12:45.162029: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (256): \tTotal Chunks: 11, Chunks in use: 11. 2.8KiB allocated for chunks. 2.8KiB in use in bin. 68B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162043: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162066: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162079: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162092: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162104: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162116: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162128: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162153: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162159: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162165: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162172: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162178: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162184: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162201: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162207: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162213: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162219: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162225: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162234: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 133.06MiB allocated for chunks. 133.06MiB in use in bin. 89.42MiB client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162243: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-10 20:12:45.162250: I external/local_tsl/tsl/framework/bfc_allocator.cc:1067] Bin for 89.42MiB was 64.00MiB, Chunk State: \n",
      "2024-07-10 20:12:45.162256: I external/local_tsl/tsl/framework/bfc_allocator.cc:1080] Next region of size 139526144\n",
      "2024-07-10 20:12:45.162263: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000000 of size 256 next 1\n",
      "2024-07-10 20:12:45.162269: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000100 of size 1280 next 2\n",
      "2024-07-10 20:12:45.162274: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000600 of size 256 next 3\n",
      "2024-07-10 20:12:45.162280: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000700 of size 256 next 4\n",
      "2024-07-10 20:12:45.162285: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000800 of size 256 next 5\n",
      "2024-07-10 20:12:45.162290: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000900 of size 256 next 6\n",
      "2024-07-10 20:12:45.162295: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000a00 of size 256 next 7\n",
      "2024-07-10 20:12:45.162300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000b00 of size 256 next 8\n",
      "2024-07-10 20:12:45.162305: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000c00 of size 256 next 9\n",
      "2024-07-10 20:12:45.162310: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000d00 of size 256 next 10\n",
      "2024-07-10 20:12:45.162316: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000e00 of size 256 next 11\n",
      "2024-07-10 20:12:45.162321: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e000f00 of size 256 next 12\n",
      "2024-07-10 20:12:45.162326: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7fe20e001000 of size 139522048 next 18446744073709551615\n",
      "2024-07-10 20:12:45.162331: I external/local_tsl/tsl/framework/bfc_allocator.cc:1105]      Summary of in-use Chunks by size: \n",
      "2024-07-10 20:12:45.162339: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 11 Chunks of size 256 totalling 2.8KiB\n",
      "2024-07-10 20:12:45.162345: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-07-10 20:12:45.162351: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 139522048 totalling 133.06MiB\n",
      "2024-07-10 20:12:45.162358: I external/local_tsl/tsl/framework/bfc_allocator.cc:1112] Sum Total of in-use chunks: 133.06MiB\n",
      "2024-07-10 20:12:45.162363: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Total bytes in pool: 139526144 memory_limit_: 139526144 available bytes: 0 curr_region_allocation_bytes_: 279052288\n",
      "2024-07-10 20:12:45.162372: I external/local_tsl/tsl/framework/bfc_allocator.cc:1119] Stats: \n",
      "Limit:                       139526144\n",
      "InUse:                       139526144\n",
      "MaxInUse:                    139526144\n",
      "NumAllocs:                          13\n",
      "MaxAllocSize:                139522048\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-07-10 20:12:45.162379: W external/local_tsl/tsl/framework/bfc_allocator.cc:499] ********************************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "2024-07-10 20:12:45.162398: W tensorflow/core/framework/op_kernel.cc:1827] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2024-07-10 20:12:45.162410: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the tokenizer and model from Hugging Face\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle-bert/bert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m TFAutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:2894\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2892\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild_in_name_scope()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2894\u001b[0m     model\u001b[38;5;241m.\u001b[39mbuild_in_name_scope()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[1;32m   2897\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1129\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build_in_name_scope\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_in_name_scope\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/models/bert/modeling_tf_bert.py:1805\u001b[0m, in \u001b[0;36mTFBertForSequenceClassification.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1805\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1807\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mname):\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/models/bert/modeling_tf_bert.py:1032\u001b[0m, in \u001b[0;36mTFBertMainLayer.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1032\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mname):\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/models/bert/modeling_tf_bert.py:160\u001b[0m, in \u001b[0;36mTFBertEmbeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    161\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    162\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    163\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    168\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    169\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtype_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    170\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    171\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/base_layer.py:699\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[1;32m    697\u001b[0m     getter \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(getter, layout\u001b[38;5;241m=\u001b[39mlayout)\n\u001b[0;32m--> 699\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_variable_with_custom_getter(\n\u001b[1;32m    700\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    701\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# `Trackable` method.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     getter\u001b[38;5;241m=\u001b[39mgetter,\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Manage errors in Layer rather than Trackable.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     initializer\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[1;32m    708\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    709\u001b[0m     constraint\u001b[38;5;241m=\u001b[39mconstraint,\n\u001b[1;32m    710\u001b[0m     trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m    711\u001b[0m     use_resource\u001b[38;5;241m=\u001b[39muse_resource,\n\u001b[1;32m    712\u001b[0m     collections\u001b[38;5;241m=\u001b[39mcollections_arg,\n\u001b[1;32m    713\u001b[0m     synchronization\u001b[38;5;241m=\u001b[39msynchronization,\n\u001b[1;32m    714\u001b[0m     aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m    715\u001b[0m     caching_device\u001b[38;5;241m=\u001b[39mcaching_device,\n\u001b[1;32m    716\u001b[0m )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[: variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:492\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    483\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    484\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 492\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m getter(\n\u001b[1;32m    493\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    494\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m    495\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    496\u001b[0m     initializer\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_for_getter)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/base_layer_utils.py:137\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m    130\u001b[0m     use_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf1\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[1;32m    138\u001b[0m         initial_value\u001b[38;5;241m=\u001b[39minit_val,\n\u001b[1;32m    139\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    140\u001b[0m         trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m    141\u001b[0m         caching_device\u001b[38;5;241m=\u001b[39mcaching_device,\n\u001b[1;32m    142\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mvariable_dtype,\n\u001b[1;32m    143\u001b[0m         validate_shape\u001b[38;5;241m=\u001b[39mvalidate_shape,\n\u001b[1;32m    144\u001b[0m         constraint\u001b[38;5;241m=\u001b[39mconstraint,\n\u001b[1;32m    145\u001b[0m         use_resource\u001b[38;5;241m=\u001b[39muse_resource,\n\u001b[1;32m    146\u001b[0m         collections\u001b[38;5;241m=\u001b[39mcollections,\n\u001b[1;32m    147\u001b[0m         synchronization\u001b[38;5;241m=\u001b[39msynchronization,\n\u001b[1;32m    148\u001b[0m         aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m    149\u001b[0m         shape\u001b[38;5;241m=\u001b[39mvariable_shape \u001b[38;5;28;01mif\u001b[39;00m variable_shape \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m         experimental_enable_variable_lifting\u001b[38;5;241m=\u001b[39mexperimental_enable_variable_lifting,  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtensor\u001b[38;5;241m.\u001b[39mDVariable(\n\u001b[1;32m    154\u001b[0m         initial_value\u001b[38;5;241m=\u001b[39minit_val,\n\u001b[1;32m    155\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         shape\u001b[38;5;241m=\u001b[39mvariable_shape \u001b[38;5;28;01mif\u001b[39;00m variable_shape \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    165\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/initializers/initializers.py:525\u001b[0m, in \u001b[0;36mTruncatedNormal.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     _ensure_keras_seeded()\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mcall_with_layout(\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator\u001b[38;5;241m.\u001b[39mtruncated_normal,\n\u001b[1;32m    518\u001b[0m         layout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         nonce,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator\u001b[38;5;241m.\u001b[39mtruncated_normal(\n\u001b[1;32m    526\u001b[0m     shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstddev, dtype, nonce\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/backend.py:2144\u001b[0m, in \u001b[0;36mRandomGenerator.truncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2143\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mstateless_truncated_normal(\n\u001b[1;32m   2145\u001b[0m         shape\u001b[38;5;241m=\u001b[39mshape, mean\u001b[38;5;241m=\u001b[39mmean, stddev\u001b[38;5;241m=\u001b[39mstddev, dtype\u001b[38;5;241m=\u001b[39mdtype, seed\u001b[38;5;241m=\u001b[39mseed\n\u001b[1;32m   2146\u001b[0m     )\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mtruncated_normal(\n\u001b[1;32m   2148\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2149\u001b[0m     mean\u001b[38;5;241m=\u001b[39mmean,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2152\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2153\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: "
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # Load the tokenizer and model from Hugging Face\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676aeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
