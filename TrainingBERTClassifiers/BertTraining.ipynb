{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cafc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4e6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c249c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 21:48:22.448965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-18 21:48:22.495084: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-18 21:48:22.495158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-18 21:48:22.523988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 21:48:24.151870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "import pandas as pd \n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930180eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:0\"))\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc9b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba94512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 21:48:31.999843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 146 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "2024-07-18 21:48:32.027048: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1566] failed to allocate 146.06MiB (153157632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b7ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "LOG: Torch allocated Memory:                 0.00 MB\n",
      "LOG: Torch cached Memory:                 0.00 MB\n",
      "LOG: TensorFlow, 0: Current memory usage:             0.00 MB\n",
      "LOG: TensorFlow, 0: Peak memory usage:             0.00 MB\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "#model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c676aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now working with the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2419cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/home/rpierson/Topic_Files/topic_9.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4106ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding= \"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37da9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1dc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "train_encodings = tokenizer(\n",
    "    train_df['Combined_Text'].tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=max_length\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_df['Combined_Text'].tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2085a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = {key: torch.tensor(val) for key, val in train_encodings.items()}\n",
    "val_inputs = {key: torch.tensor(val) for key, val in val_encodings.items()}\n",
    "train_labels = torch.tensor(train_df['Priority'].values - 1)  # Adjust labels to start from 0\n",
    "val_labels = torch.tensor(val_df['Priority'].values - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292c6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = tf.data.Dataset.from_tensor_slices((train_encodings, train_labels)).shuffle(len(train_df)).batch(15)\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((val_encodings, val_labels)).batch(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd609a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#    dict(train_encodings),\n",
    "#    train_df['Priority']\n",
    "#)).shuffle(len(train_df)).batch(15)\n",
    "\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#    dict(val_encodings),\n",
    "#    val_df['Priority']\n",
    "#)).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aac828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        label = self.labels[idx]\n",
    "        return item, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "val_dataset = CustomDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d13d7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ea5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f5b5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_ids = inputs['input_ids']\n",
    "#attention_mask = inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75e4f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cf6014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/1324], Loss: 0.6857\n",
      "Epoch [1/1], Step [200/1324], Loss: 0.5865\n",
      "Epoch [1/1], Step [300/1324], Loss: 0.5965\n",
      "Epoch [1/1], Step [400/1324], Loss: 0.6349\n",
      "Epoch [1/1], Step [500/1324], Loss: 0.6049\n",
      "Epoch [1/1], Step [600/1324], Loss: 0.6100\n",
      "Epoch [1/1], Step [700/1324], Loss: 0.6277\n",
      "Epoch [1/1], Step [800/1324], Loss: 0.5836\n",
      "Epoch [1/1], Step [900/1324], Loss: 0.5922\n",
      "Epoch [1/1], Step [1000/1324], Loss: 0.5728\n",
      "Epoch [1/1], Step [1100/1324], Loss: 0.5844\n",
      "Epoch [1/1], Step [1200/1324], Loss: 0.5568\n",
      "Epoch [1/1], Step [1300/1324], Loss: 0.5767\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_epochs = 1\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for step, (batch, labels) in enumerate(train_loader):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            logits = logits.view(-1, 5)\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{step + 1}/{len(train_loader)}], Loss: {total_loss / 100:.4f}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54a2b88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rpierson/githubPierson/TrainingBERTClassifiers/BERTTrained/topic_pred_9.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "extract_dir = '/home/rpierson/githubPierson/TrainingBERTClassifiers/BERTTrained'\n",
    "topic_pred_file = os.path.join(extract_dir, f'topic_pred_9.pkl')\n",
    "joblib.dump(model, topic_pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ac5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
