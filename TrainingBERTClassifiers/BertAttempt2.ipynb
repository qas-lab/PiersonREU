{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cafc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4e6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c249c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 20:30:27.656296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 20:30:27.687223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 20:30:27.687254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 20:30:27.707061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 20:30:28.495309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizerFast, TFAutoModelForTokenClassification\n",
    "import pandas as pd \n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930180eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc9b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-07-12 20:30:32.180437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10532 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba94512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b7ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "LOG: Torch allocated Memory:                 0.00 MB\n",
      "LOG: Torch cached Memory:                 0.00 MB\n",
      "LOG: TensorFlow, 0: Current memory usage:             416.42 MB\n",
      "LOG: TensorFlow, 0: Peak memory usage:             505.58 MB\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "if torch.cuda.is_available():\n",
    "        print(f\"LOG: Torch allocated Memory: \\\n",
    "                {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "        print(f\"LOG: Torch cached Memory: \\\n",
    "                {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    zero_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    print(f\"LOG: TensorFlow, 0: Current memory usage: \\\n",
    "            {zero_info['current'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "    print(f\"LOG: TensorFlow, 0: Peak memory usage: \\\n",
    "            {zero_info['peak'] / 1024 ** 2:.2f} MB\", flush=True)\n",
    "\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "model.compile(optimizer='Ftrl', loss='sparse_categorical_crossentropy', metrics = ['Accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c676aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now working with the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2419cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/home/rpierson/Topic_Files/topic_0.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4106ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding= \"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37da9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1dc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenize function to the 'Combined_Text' column\n",
    "#for x in range(len(train_df)):\n",
    "#    train_df.loc[x, 'Combined_Text'] = tokenize_function(train_df.loc[x, 'Combined_Text'])\n",
    "\n",
    "\n",
    "#train_df['Combined_Text'] = train_df['Combined_Text'].apply(tokenize_function)\n",
    "#val_df['Combined_Text'] = val_df['Combined_Text'].apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2085a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(\n",
    "    train_df['Combined_Text'].tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    val_df['Combined_Text'].tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3282c92c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_inputs = {\n",
    "    'input_ids': tf.constant(train_encodings['input_ids']),\n",
    "    'attention_mask': tf.constant(train_encodings['attention_mask'])\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    'input_ids': tf.constant(val_encodings['input_ids']),\n",
    "    'attention_mask': tf.constant(val_encodings['attention_mask'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9de4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.constant(train_df['Priority'].values)  # Shape (num_samples,)\n",
    "val_labels = tf.constant(val_df['Priority'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aaf1968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input_ids shape: (824, 512)\n",
      "Train attention_mask shape: (824, 512)\n",
      "Val input_ids shape: (206, 512)\n",
      "Val attention_mask shape: (206, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train input_ids shape:\", tf.constant(train_encodings['input_ids']).shape)\n",
    "print(\"Train attention_mask shape:\", tf.constant(train_encodings['attention_mask']).shape)\n",
    "print(\"Val input_ids shape:\", tf.constant(val_encodings['input_ids']).shape)\n",
    "print(\"Val attention_mask shape:\", tf.constant(val_encodings['attention_mask']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292c6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_encodings, train_labels)).shuffle(len(train_df)).batch(15)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_encodings, val_labels)).batch(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd609a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#    dict(train_encodings),\n",
    "#    train_df['Priority']\n",
    "#)).shuffle(len(train_df)).batch(15)\n",
    "\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#    dict(val_encodings),\n",
    "#    val_df['Priority']\n",
    "#)).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d13d7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch input_ids shape: (15, 512)\n",
      "Train batch attention_mask shape: (15, 512)\n",
      "Train batch labels shape: (15,)\n",
      "Val batch input_ids shape: (15, 512)\n",
      "Val batch attention_mask shape: (15, 512)\n",
      "Val batch labels shape: (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 20:30:36.532106: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-12 20:30:36.542468: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_dataset.take(1):\n",
    "    print(\"Train batch input_ids shape:\", inputs['input_ids'].shape)\n",
    "    print(\"Train batch attention_mask shape:\", inputs['attention_mask'].shape)\n",
    "    print(\"Train batch labels shape:\", labels.shape)\n",
    "\n",
    "for inputs, labels in val_dataset.take(1):\n",
    "    print(\"Val batch input_ids shape:\", inputs['input_ids'].shape)\n",
    "    print(\"Val batch attention_mask shape:\", inputs['attention_mask'].shape)\n",
    "    print(\"Val batch labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "252ea5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (15, 512, 5)\n",
      "Expected labels shape: (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 20:30:37.528879: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_dataset.take(1):\n",
    "    outputs = model(inputs)\n",
    "    print(\"Model output shape:\", outputs.logits.shape)\n",
    "    print(\"Expected labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f54120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b982ec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7f4a6f965580> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7f4a6f965580> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1643, in train_step  *\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/compile_utils.py\", line 620, in update_state  *\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/metrics/base_metric.py\", line 153, in decorated  *\n        result = update_state_fn(*args, **kwargs)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/metrics/base_metric.py\", line 140, in update_state_fn  *\n        return ag_update_state(*args, **kwargs)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/metrics/confusion_metrics.py\", line 481, in update_state  *\n        sample_weight=sample_weight,\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/utils/metrics_utils.py\", line 672, in update_confusion_matrix_variables  *\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 512, 5) and (None,) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     train_dataset,\n\u001b[1;32m      3\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m  \u001b[38;5;66;03m# Adjust the number of epochs based on your needs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1161\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1160\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filewy14or_g.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1g4r40vg.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     43\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mjit_compile, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun, (ag__\u001b[38;5;241m.\u001b[39mld(run_step),), \u001b[38;5;28mdict\u001b[39m(args\u001b[38;5;241m=\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(data),)), fscope)\n\u001b[1;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(reduce_per_replica), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_strategy), \u001b[38;5;28mdict\u001b[39m(reduction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_reduction_method), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1g4r40vg.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrain_step, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[1;32m     20\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file399_m_z9.py:411\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    409\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(loss) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_23, else_body_23, get_state_24, set_state_24, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    410\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28mdict\u001b[39m(tape\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tape)), fscope)\n\u001b[0;32m--> 411\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(y), ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(sample_weight)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    412\u001b[0m return_metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_26\u001b[39m():\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenyzhjda6.py:163\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    161\u001b[0m mask \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    162\u001b[0m metric_objs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_objs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(zip_args)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body_2, get_state_9, set_state_9, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(y_t, y_p, sw, metric_objs, weighted_metric_objs)\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenyzhjda6.py:151\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state.<locals>.loop_body_2\u001b[0;34m(itr_2)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m y_t, sw, y_p\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(continue_), if_body_6, else_body_6, get_state_8, set_state_8, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_t\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenyzhjda6.py:106\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state.<locals>.loop_body_2.<locals>.if_body_6\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(continue__1), if_body_3, else_body_3, get_state_3, set_state_3, (), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mld(metric_objs), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state_4, set_state_4, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_obj\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_7\u001b[39m():\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenyzhjda6.py:105\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state.<locals>.loop_body_2.<locals>.if_body_6.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_3\u001b[39m():\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(continue__1), if_body_3, else_body_3, get_state_3, set_state_3, (), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenyzhjda6.py:101\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state.<locals>.loop_body_2.<locals>.if_body_6.<locals>.loop_body.<locals>.if_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body_3\u001b[39m():\n\u001b[0;32m--> 101\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(metric_obj)\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(y_t), ag__\u001b[38;5;241m.\u001b[39mld(y_p)), \u001b[38;5;28mdict\u001b[39m(sample_weight\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(mask)), fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedlot6omk.py:38\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__decorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mld(metric_obj)\u001b[38;5;241m.\u001b[39mweights, \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state_1, set_state_1, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf_utils)\u001b[38;5;241m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)):\n\u001b[0;32m---> 38\u001b[0m     result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(update_state_fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_2\u001b[39m():\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (result,)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filexass6h2d.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ag_update_state), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileucrarn6f.py:26\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(metrics_utils)\u001b[38;5;241m.\u001b[39mupdate_confusion_matrix_variables, ({ag__\u001b[38;5;241m.\u001b[39mld(metrics_utils)\u001b[38;5;241m.\u001b[39mConfusionMatrix\u001b[38;5;241m.\u001b[39mTRUE_POSITIVES: ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrue_positives, ag__\u001b[38;5;241m.\u001b[39mld(metrics_utils)\u001b[38;5;241m.\u001b[39mConfusionMatrix\u001b[38;5;241m.\u001b[39mFALSE_POSITIVES: ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfalse_positives}, ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28mdict\u001b[39m(thresholds\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mthresholds, thresholds_distributed_evenly\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_thresholds_distributed_evenly, top_k\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtop_k, class_id\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mclass_id, sample_weight\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(sample_weight)), fscope)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevuu6meoi.py:530\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_confusion_matrix_variables\u001b[0;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights, thresholds_distributed_evenly)\u001b[0m\n\u001b[1;32m    528\u001b[0m thresholds_with_epsilon \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresholds_with_epsilon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    529\u001b[0m pred_is_pos \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_is_pos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 530\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(variables_to_update) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_20, else_body_20, get_state_21, set_state_21, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_is_neg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresholds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresholds_with_epsilon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevuu6meoi.py:184\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_confusion_matrix_variables.<locals>.else_body_20\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m     y_pred, y_true, sample_weight \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(losses_utils)\u001b[38;5;241m.\u001b[39msqueeze_or_expand_dimensions, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(y_true)), \u001b[38;5;28mdict\u001b[39m(sample_weight\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(sample_weight)), fscope)\n\u001b[1;32m    183\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(sample_weight) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_5, else_body_5, get_state_5, set_state_5, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(y_pred)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39massert_is_compatible_with, (ag__\u001b[38;5;241m.\u001b[39mld(y_true)\u001b[38;5;241m.\u001b[39mshape,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (y_pred,)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1643, in train_step  *\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/engine/compile_utils.py\", line 620, in update_state  *\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/metrics/base_metric.py\", line 153, in decorated  *\n        result = update_state_fn(*args, **kwargs)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/metrics/base_metric.py\", line 140, in update_state_fn  *\n        return ag_update_state(*args, **kwargs)\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/metrics/confusion_metrics.py\", line 481, in update_state  *\n        sample_weight=sample_weight,\n    File \"/home/rpierson/anaconda3/envs/secondenvi/lib/python3.11/site-packages/tf_keras/src/utils/metrics_utils.py\", line 672, in update_confusion_matrix_variables  *\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 512, 5) and (None,) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=15  # Adjust the number of epochs based on your needs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf6014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2b88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ac5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
